{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import welch, hilbert\n",
    "from scipy.stats import skew, kurtosis\n",
    "import natsort\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temporal_features(signal):\n",
    "    \"\"\"Extract temporal features for a single EEG channel.\"\"\"\n",
    "    features = {\n",
    "        \"mean\": np.mean(signal),\n",
    "        \"std\": np.std(signal),\n",
    "        \"skewness\": skew(signal),\n",
    "        \"kurtosis\": kurtosis(signal),\n",
    "        \"peak_to_peak\": np.ptp(signal),\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def extract_frequency_features(signal, sf=128):\n",
    "    \"\"\"Extract frequency features using Welch's method.\"\"\"\n",
    "    f, psd = welch(signal, fs=sf, nperseg=sf*2)\n",
    "    total_power = np.sum(psd)\n",
    "    features = {\n",
    "        \"abs_delta_power\": np.sum(psd[(f >= 0.5) & (f < 4)]),  #  Absolute power in delta band\n",
    "        \"abs_theta_power\": np.sum(psd[(f >= 4) & (f < 8)]),  # Absolute power in theta band\n",
    "        \"abs_alpha_power\": np.sum(psd[(f >= 8) & (f < 12)]),  # Absolute power in alpha band\n",
    "        \"abs_beta_power\": np.sum(psd[(f >= 12) & (f < 30)]),  # Absolute power in beta band\n",
    "        \"rel_gamma_power\": np.sum(psd[(f >= 30)]) / total_power,  # Relative power in gamma band\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def compute_visibility_graph(signal, chunk_size=64):  # 64 samples = 0.5 seconds\n",
    "    \"\"\"Convert signal to visibility graph and extract graph features.\"\"\"\n",
    "    def visibility_graph_chunk(chunk):\n",
    "        G = nx.Graph()\n",
    "        n = len(chunk)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                k_range = np.arange(i + 1, j)\n",
    "                if np.all(chunk[k_range] < chunk[i] + (chunk[j] - chunk[i]) * (k_range - i) / (j - i)):\n",
    "                    G.add_edge(i, j)\n",
    "        return G\n",
    "\n",
    "    num_chunks = len(signal) // chunk_size + (1 if len(signal) % chunk_size != 0 else 0)\n",
    "    all_degrees = []\n",
    "    all_clustering_coeffs = []\n",
    "    all_path_lengths = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        chunk = signal[i * chunk_size:(i + 1) * chunk_size]\n",
    "        G = visibility_graph_chunk(chunk)\n",
    "        degrees = [degree for node, degree in G.degree()]\n",
    "        all_degrees.extend(degrees)\n",
    "        all_clustering_coeffs.append(nx.average_clustering(G))\n",
    "        if nx.is_connected(G):\n",
    "            all_path_lengths.append(nx.average_shortest_path_length(G))\n",
    "\n",
    "    avg_degree = np.mean(all_degrees)\n",
    "    degree_entropy = -np.sum([p * np.log2(p) for p in np.bincount(all_degrees) / len(all_degrees) if p > 0])\n",
    "    avg_clustering_coeff = np.mean(all_clustering_coeffs)\n",
    "    avg_path_length = np.mean(all_path_lengths) if all_path_lengths else float('inf')\n",
    "\n",
    "    features = {\n",
    "        \"avg_degree\": avg_degree,\n",
    "        \"degree_entropy\": degree_entropy,\n",
    "        \"avg_clustering_coeff\": avg_clustering_coeff,\n",
    "        \"avg_path_length\": avg_path_length,\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "def extract_amplitude_modulation(signal):\n",
    "    \"\"\"Extract amplitude modulation features.\"\"\"\n",
    "    analytic_signal = hilbert(signal)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "    features = {\n",
    "        \"am_mean\": np.mean(amplitude_envelope),\n",
    "        \"am_std\": np.std(amplitude_envelope),\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing activity: Arithmetic\n",
      "........................................\n",
      "Processing activity: Mirror_image\n",
      "........................................\n",
      "Processing activity: Relax\n",
      "........................................\n",
      "Processing activity: Stroop\n",
      "........................................\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "base_dir = \"Data/Preprocessed\"\n",
    "activities = [\"Arithmetic\", \"Mirror_image\", \"Relax\", \"Stroop\"]\n",
    "\n",
    "# Main processing loop\n",
    "results = []\n",
    "\n",
    "for activity in activities:\n",
    "    print(f\"Processing activity: {activity}\")\n",
    "    activity_dir = os.path.join(base_dir, activity)\n",
    "    for i, file in enumerate(natsort.natsorted(os.listdir(activity_dir))):\n",
    "        if file.endswith(\".csv\"):\n",
    "            if i % 3 == 0:\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "            file_path = os.path.join(activity_dir, file)\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Extract time points and EEG signals\n",
    "            time = data.iloc[:, 0]\n",
    "            signals = data.iloc[:, 1:].values  # All EEG channels\n",
    "            \n",
    "            for channel_idx, signal in enumerate(signals.T):\n",
    "                # Combine all feature extraction\n",
    "                temporal_features = extract_temporal_features(signal)\n",
    "                frequency_features = extract_frequency_features(signal)\n",
    "                vg_features = compute_visibility_graph(signal)\n",
    "                am_features = extract_amplitude_modulation(signal)\n",
    "                \n",
    "                # Merge features\n",
    "                features = {\n",
    "                    \"activity\": activity,\n",
    "                    \"file\": file,\n",
    "                    \"channel\": f\"channel_{channel_idx + 1}\",\n",
    "                    **temporal_features,\n",
    "                    **frequency_features,\n",
    "                    **vg_features,\n",
    "                    **am_features,\n",
    "                }\n",
    "                results.append(features)\n",
    "    print()  # New line after each activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete. Results saved to eeg_features.csv.\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "features_df = pd.DataFrame(results)\n",
    "features_df.to_csv(\"eeg_features.csv\", index=False)\n",
    "print(\"Feature extraction complete. Results saved to eeg_features.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam40",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
